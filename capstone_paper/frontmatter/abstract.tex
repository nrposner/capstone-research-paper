\newpage
\pagenumbering{roman}
\setcounter{page}{1}
\section{Abstract}
\noindent

This work presents a structured pipeline for co-creative drone light show design that integrates large language models (LLMs) with analytical validation and deployment systems. Rather than treating LLMs as autonomous choreographers, the study reframes them as semantic front ends that generate interpretable creative intent, which is then translated into physically valid and executable drone formations. The proposed framework couples language-based generative interfaces with analytic solvers and the \textbf{Skybrush Studio API}, which performs safety verification, trajectory optimization, and compilation into deployable show formats. Through this integration, we demonstrate how semantic creativity and syntactic rigor can coexist within a single workflow, enabling intuitive yet verifiable design of drone swarm performances. The findings clarify where language-driven generation adds value, where it requires analytic reinforcement, and how modular architectures can support collaboration between human designers, generative models, and production-grade control software.

\vspace{1in}
\noindent \textbf{Keywords:} drone light shows, large language models, semantic-syntactic integration, Skybrush Studio API, generative design pipeline, creative robotics, human-AI collaboration, formation sampling, trajectory optimization
